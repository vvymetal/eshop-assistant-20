{
  "README.md": "# OpenAI Assistant Streaming with Function Calling in FastAPI\n\nThis project showcases how you can use asynchronous streaming with OpenAI assistant and at the same time utilize function calling\nin FastAPI.\n\nYou can read about it in detail in the following blog post: [OpenAI Assistant Streaming with Function Calling in FastAPI](https://medium.com/@meeran2003/async-streaming-openai-assistant-api-with-function-calling-in-fastapi-0dfe5935f238)\n\n![OpenAI Assistant Streaming with Function Calling in FastAPI](./demo.png?raw=true \"Demo\")\n\n## Description\n\nThis project demonstrates how you can use FastAPI to create a real-time chat interface that communicates with OpenAI's GPT models for automated responses. The application also supports function calling, allowing you to execute commands and retrieve information in real-time.\n\n## Features\n\n- Asynchronous streaming for real-time chat communication.\n- Function calling for executing commands and retrieving information.\n- Integration with OpenAI's GPT models for automated responses.\n- Weather information retrieval using the OpenWeather API.\n- Text to Speech and Speech to Text using web APIs.\n- Chat interface for real-time communication.\n\n## Getting Started\n\n### Dependencies\n\n- Python 3.8 or higher\n- FastAPI\n- OpenAI API\n- aiohttp, httpx for asynchronous HTTP requests\n\nRefer to `requirements.txt` for a complete list of dependencies.\n\n### Installing\n\n1. Clone the repository to your local machine.\n2. Create a virtual environment:\n\n```sh\npython -m venv env\n```\n\n3. Activate the virtual environment:\n\n- On Windows:\n\n```sh\nenv\\Scripts\\activate\n```\n\n- On Unix or MacOS:\n\n```sh\nsource env/bin/activate\n```\n\n4. Install the required packages:\n\n```sh\npip install -r requirements.txt\n```\n\n### Configuration\n\n- Copy `.env.development` to `.env` and adjust the configuration variables as needed.\n- Ensure you have valid API keys for OpenAI and OpenWeather APIs set in your `.env` file.\n\n### Running the Application\n\n1. Start the application:\n\n```sh\nuvicorn main:app --reload\n```\n\n2. Visit `http://127.0.0.1:8000` in your web browser to access the chat interface.\n\n## Usage\n\n- Use the chat interface to communicate in real-time.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit pull requests or open issues to suggest improvements or add new features.\n",
  "extract_project_code.py": "import os\nimport json\nimport fnmatch\nfrom pathlib import Path\n\ndef load_gitignore(project_path):\n    gitignore_path = os.path.join(project_path, '.gitignore')\n    ignore_patterns = []\n    if os.path.exists(gitignore_path):\n        with open(gitignore_path, 'r') as f:\n            ignore_patterns = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n    return ignore_patterns\n\ndef should_ignore(path, ignore_patterns):\n    path = Path(path)\n    for pattern in ignore_patterns:\n        if fnmatch.fnmatch(str(path), pattern) or any(fnmatch.fnmatch(str(parent), pattern) for parent in path.parents):\n            return True\n    return False\n\ndef should_include_file(file_path, ignore_patterns):\n    # Seznam přípon souborů, které chceme zahrnout\n    include_extensions = ['.py', '.js', '.jsx', '.html', '.css']\n    # Seznam souborů, které chceme vždy zahrnout\n    always_include = ['README.md', '.env.example']\n    \n    _, file_extension = os.path.splitext(file_path)\n    file_name = os.path.basename(file_path)\n    \n    # Kontrola, zda soubor není ignorován pomocí .gitignore\n    if should_ignore(file_path, ignore_patterns):\n        return False\n\n    return file_extension in include_extensions or file_name in always_include\n\ndef extract_project_structure(project_path):\n    project_structure = {}\n    ignore_patterns = load_gitignore(project_path)\n    \n    for root, dirs, files in os.walk(project_path):\n        # Explicitně vynecháváme adresář venv\n        if 'venv' in dirs:\n            dirs.remove('venv')\n        \n        for file in files:\n            file_path = os.path.join(root, file)\n            if should_include_file(file_path, ignore_patterns):\n                relative_path = os.path.relpath(file_path, project_path)\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    try:\n                        content = f.read()\n                        project_structure[relative_path] = content\n                    except UnicodeDecodeError:\n                        print(f\"Skipping binary file: {relative_path}\")\n    \n    return project_structure\n\ndef save_project_structure(project_structure, output_file):\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(project_structure, f, indent=2, ensure_ascii=False)\n\nif __name__ == \"__main__\":\n    project_path = \"/Users/vladimirvymetal/python/eshop-assistant\"  # Upravte cestu k vašemu projektu\n    output_file = \"project_structure.json\"\n    \n    project_structure = extract_project_structure(project_path)\n    save_project_structure(project_structure, output_file)\n    \n    print(f\"Project structure and contents saved to {output_file}\")",
  "frontend/src/components/ChatWidget.jsx": "import React, { useState, useEffect, useRef } from 'react';\nimport { Button, Input, List, Card, Image, Modal } from 'antd';\nimport { ShoppingCartOutlined, SendOutlined } from '@ant-design/icons';\n\nconst EshopAssistantChatWidget = ({ apiEndpoint, onAddToCart }) => {\n  const [messages, setMessages] = useState([]);\n  const [inputMessage, setInputMessage] = useState('');\n  const [isLoading, setIsLoading] = useState(false);\n  const [workingCart, setWorkingCart] = useState([]);\n  const [quizData, setQuizData] = useState(null);\n  const [showQuiz, setShowQuiz] = useState(false);\n  const chatEndRef = useRef(null);\n\n  useEffect(() => {\n    chatEndRef.current?.scrollIntoView({ behavior: \"smooth\" });\n  }, [messages]);\n\n  const sendMessage = async () => {\n    if (!inputMessage.trim()) return;\n\n    setIsLoading(true);\n    setMessages(prev => [...prev, { role: 'user', content: inputMessage }]);\n    setInputMessage('');\n\n    try {\n      const response = await fetch(`${apiEndpoint}/chat`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ message: inputMessage }),\n      });\n\n      if (response.body) {\n        const reader = response.body.getReader();\n        let partialResponse = '';\n\n        while (true) {\n          const { done, value } = await reader.read();\n          if (done) break;\n\n          partialResponse += new TextDecoder().decode(value);\n          const chunks = partialResponse.split('\\n\\n');\n          \n          for (let chunk of chunks) {\n            if (chunk.startsWith('data: ')) {\n              const data = JSON.parse(chunk.slice(6));\n              handleStreamedResponse(data);\n            }\n          }\n\n          partialResponse = chunks[chunks.length - 1];\n        }\n      }\n    } catch (error) {\n      console.error('Error sending message:', error);\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const handleStreamedResponse = (data) => {\n    if (data.type === 'text') {\n      setMessages(prev => {\n        const lastMessage = prev[prev.length - 1];\n        if (lastMessage.role === 'assistant') {\n          return [...prev.slice(0, -1), { ...lastMessage, content: lastMessage.content + data.content }];\n        } else {\n          return [...prev, { role: 'assistant', content: data.content }];\n        }\n      });\n    } else if (data.type === 'product') {\n      setWorkingCart(prev => [...prev, data.product]);\n    } else if (data.type === 'quiz') {\n      setQuizData(data.quiz);\n      setShowQuiz(true);\n    }\n  };\n\n  const renderMessage = (message) => (\n    <List.Item>\n      <Card>\n        <strong>{message.role === 'user' ? 'You:' : 'Assistant:'}</strong>\n        <p>{message.content}</p>\n      </Card>\n    </List.Item>\n  );\n\n  const renderWorkingCart = () => (\n    <Modal\n      title=\"Working Cart\"\n      visible={workingCart.length > 0}\n      onOk={() => onAddToCart(workingCart)}\n      onCancel={() => setWorkingCart([])}\n    >\n      <List\n        dataSource={workingCart}\n        renderItem={item => (\n          <List.Item>\n            <Card>\n              <Image src={item.image} width={50} />\n              <p>{item.name} - ${item.price}</p>\n            </Card>\n          </List.Item>\n        )}\n      />\n    </Modal>\n  );\n\n  const renderQuiz = () => (\n    <Modal\n      title={quizData?.title}\n      visible={showQuiz}\n      onOk={() => setShowQuiz(false)}\n      onCancel={() => setShowQuiz(false)}\n    >\n      {quizData?.questions.map((question, index) => (\n        <div key={index}>\n          <p>{question.text}</p>\n          {question.options.map((option, optionIndex) => (\n            <Button key={optionIndex} onClick={() => handleQuizAnswer(index, optionIndex)}>\n              {option}\n            </Button>\n          ))}\n        </div>\n      ))}\n    </Modal>\n  );\n\n  const handleQuizAnswer = (questionIndex, answerIndex) => {\n    // Implementace logiky pro zpracování odpovědí na kvíz\n    console.log(`Question ${questionIndex}, Answer ${answerIndex}`);\n  };\n\n  return (\n    <div className=\"chat-widget\">\n      <List\n        className=\"message-list\"\n        dataSource={messages}\n        renderItem={renderMessage}\n      />\n      <div ref={chatEndRef} />\n      <div className=\"chat-input\">\n        <Input\n          value={inputMessage}\n          onChange={(e) => setInputMessage(e.target.value)}\n          onPressEnter={sendMessage}\n          placeholder=\"Type a message...\"\n          disabled={isLoading}\n        />\n        <Button onClick={sendMessage} icon={<SendOutlined />} loading={isLoading}>\n          Send\n        </Button>\n        <Button onClick={() => setWorkingCart([])} icon={<ShoppingCartOutlined />}>\n          Cart ({workingCart.length})\n        </Button>\n      </div>\n      {renderWorkingCart()}\n      {renderQuiz()}\n    </div>\n  );\n};\n\nexport default EshopAssistantChatWidget;",
  "constants/__init__.py": "",
  "backend/__init__.py": "",
  "backend/main.py": "\"\"\"\n    The entry file for the FastAPI application.\n\"\"\"\n\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom .api.router import api_router\n\napp = FastAPI(title=\"Activities Suggester App\", version=\"1.0\", debug=True)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.include_router(api_router)\n",
  "backend/tools/definitions.py": "\"\"\"\n    This file contains json-schemas for the tools\n\n\"\"\"\n\nGET_WEATHER_INFORMATION = {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_weather_information\",\n        \"description\": \"Gets the weather information for a given latitude and longitude\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"latitude\": {\n                    \"type\": \"number\",\n                    \"description\": \"The latitude of the location\",\n                },\n                \"longitude\": {\n                    \"type\": \"number\",\n                    \"description\": \"The longitude of the location\",\n                },\n            },\n            \"required\": [\"latitude\", \"longitude\"],\n        },\n    },\n}\n",
  "backend/tools/__init__.py": "",
  "backend/tools/get_weather.py": "\"\"\"\n    main file for accessing services.\n\"\"\"\n\nimport os\nfrom datetime import datetime\nimport aiohttp\n\nfrom ..config.main import config\n\nos.environ[\"OPENWEATHER_API_KEY\"] = config.OPENWEATHER_API_KEY\n\nasync def get_weather_information(latitude: int, longitude: int) -> str:\n    \"\"\"Gets the weather information for a given latitude and longitude.\"\"\"\n    try:\n        url = \"https://history.openweathermap.org/data/2.5/aggregated/day\"\n        current_day, current_month = datetime.now().day, datetime.now().month\n        params = {\n            \"lat\": latitude,\n            \"lon\": longitude,\n            \"appid\": os.environ.get(\"OPENWEATHER_API_KEY\"),\n            \"month\": current_month,\n            \"day\": current_day,\n        }\n        result = None\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url, params=params) as response:\n                if response.status != 200:\n                    return \"Sorry, I couldn't find the weather information for the given location.\"\n                result = await response.json()\n        # we format the response to be more user friendly\n        result = result.get(\"result\")\n        if not result:\n            return (\n                \"Sorry, I couldn't find the weather information for the given location.\"\n            )\n        return f\"\"\"\n        For given Location:\n            Mean temperature: {result['temp']['mean']} Kelvin\n            Mean humidity: {result['humidity']['mean']} %\n            Mean wind_speed: {result['wind']['mean']} m/s\n            Mean pressure: {result['pressure']['mean']} hPa\n            Mean precipitation: {result['precipitation']['mean']} mm\n        \"\"\"\n    except Exception:  # pylint: disable=broad-except\n        return \"Sorry, I couldn't find the weather information for the given location.\"\n",
  "backend/config/__init__.py": "",
  "backend/config/prompts.py": "\"\"\"\n    This file will house all the prompts used in the application.\n\"\"\"\n\nSYS_PROMPT = \"\"\"\nYou are an AI Assistant that tells people what activities they can do based on the weather.\nWhen responding, you don't need to provide the weather information in the response.\nJust depending on the overall weather, suggest the activities.\n\"\"\"\n",
  "backend/config/main.py": "\"\"\"\n    This file contains all project configs read from env file.\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\n\nprint(\"Načítám proměnné prostředí...\")\nload_dotenv(verbose=True)\n\nclass Base(object):\n    DEBUG: bool = True\n\nclass Config(Base):\n    DEBUG: bool = True\n    OPENAI_API_KEY: str = os.getenv(\"OPENAI_API_KEY\")\n    ASSISTANT_ID: str = os.getenv(\"ASSISTANT_ID\")\n    OPENAI_MODEL: str = \"gpt-4o\"\n    OPENWEATHER_API_KEY: str = os.getenv(\"OPENWEATHER_API_KEY\")\n\nconfig = Config()\nprint(f\"OPENWEATHER_API_KEY z config: {config.OPENWEATHER_API_KEY}\")",
  "backend/utils/__init__.py": "",
  "backend/utils/stream.py": "\"\"\"\nStream related utilities.\n\"\"\"\n\nasync def stream_generator(data):\n    \"\"\"\n    Generator function to simulate streaming data.\n    \"\"\"\n    async for message in data:\n        json_data = message\n        if hasattr(message, 'model_dump_json'):\n            json_data = message.model_dump_json()\n        if isinstance(json_data, str) and json_data.startswith('data:'):\n            yield json_data\n        else:\n            yield f\"data: {json_data}\\n\\n\"\n",
  "backend/utils/singleton.py": "\"\"\"\n    Contains a Singleton Metaclass.\n\"\"\"\n\nclass Singleton(type):\n    \"\"\"\n        metaclass\n    \"\"\"\n    _instances = {}\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n        return cls._instances[cls]\n",
  "backend/api/__init__.py": "",
  "backend/api/router.py": "\"\"\"\nThis file is responsible for routing the incoming requests to the respective endpoints.\n\"\"\"\n\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi import APIRouter\nfrom fastapi.requests import Request\nfrom pydantic import BaseModel\n\nfrom ..services.chat import ChatService\nfrom ..utils.stream import stream_generator\n\napi_router = APIRouter()\nchat_service = ChatService()\n\ntemplates = Jinja2Templates(directory=\"templates\")\n\n\nclass GetChatResponseRequest(BaseModel):\n    \"\"\"\n    This class is used to validate the request for getting a chat response\n    \"\"\"\n\n    user_query: str\n\n\n@api_router.get(\"/ping\", response_class=JSONResponse)\nasync def ping():\n    \"\"\"\n    This function is used for health check of the application.\n    \"\"\"\n    return {\"message\": \"Application is Running!\", \"status\": \"success\"}\n\n\n@api_router.post(\"/chat/{chat_id}\")\nasync def get_chat_response(chat_id: str, data: GetChatResponseRequest):\n    \"\"\"\n    This function generates response for a user query\n    \"\"\"\n    query = data.user_query\n    response = chat_service.generate(chat_id, query)\n    return StreamingResponse(stream_generator(response))\n\n@api_router.get(\"/\", response_class=JSONResponse)\nasync def chat_frontend(request: Request):\n    \"\"\"\n    This function renders the chat frontend\n    \"\"\"\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
  "backend/services/assistant_setup.py": "\"\"\"\n    This class handles updates/creation of the \n    OpenAI Assistant for the chatbot\n\"\"\"\nfrom openai import AsyncOpenAI as OpenAI\nfrom ..config.main import config\n\nclass AssistantSetup:\n    \"\"\"\n    This class handles updates/creation of the\n    OpenAI Assistant for the chatbot\n    \"\"\"\n    def __init__(self, client: OpenAI, assistant_id, sys_prompt, name, tools):\n        self.client = client\n        self.assistant_id = assistant_id\n        self.tools = tools\n        self.sys_prompt = sys_prompt\n        self.name = name\n        self.model = config.OPENAI_MODEL\n\n    async def create_or_update_assistant(self):\n        \"\"\"\n        This function creates or updates the assistant\n        \"\"\"\n        assistant_id = self.assistant_id\n        if assistant_id:\n            assistant = await self.update_existing_assistant(assistant_id)\n        else:\n            assistant = await self.create_new_assistant()\n        return assistant\n\n    async def update_existing_assistant(self, assistant_id):\n        \"\"\"\n        This function updates the existing assistant\n        with the new properties\n        \"\"\"\n        try:\n            assistant = await self.client.beta.assistants.retrieve(assistant_id)\n            await self.update_assistant_properties(assistant)\n        except Exception as e: # pylint: disable=broad-except\n            print(f\"Error updating assistant: {e}\")\n            assistant = await self.create_new_assistant()\n        return assistant\n\n    async def create_new_assistant(self):\n        \"\"\"\n        This function creates a new assistant\n        \"\"\"\n        try:\n            model = self.model\n            assistant = await self.client.beta.assistants.create(\n                name=self.name,\n                instructions=self.sys_prompt,\n                model=model,\n                tools=self.tools,\n                temperature=self.get_temperature(),\n            )\n            print(\"Assistant created successfully!\", assistant.id)\n        except Exception as e: # pylint: disable=broad-except\n            print(f\"Error creating assistant: {e}\")\n            assistant = None\n        return assistant\n\n    def get_temperature(self):\n        \"\"\"\n        This function returns the temperature depending on the assistant\n        \"\"\"\n        return 0.5\n\n    async def update_assistant_properties(self, assistant):\n        \"\"\"\n        This function updates the assistant properties\n        \"\"\"\n        try:\n            assistant = await self.client.beta.assistants.update(\n                assistant.id,\n                instructions=self.sys_prompt,\n                tools=self.tools,\n                temperature=self.get_temperature(),\n            )\n        except Exception as e: # pylint: disable=broad-except\n            print(f\"Error updating assistant: {e}\")\n        return assistant\n",
  "backend/services/__init__.py": "",
  "backend/services/chat.py": "\"\"\"\n    This file contains the core functionality of the chat service.\n\"\"\"\n\nimport os\nimport asyncio\nimport json\n\nfrom openai import AsyncOpenAI as OpenAI\nfrom openai.types.beta import Assistant, Thread\nfrom openai.types.beta.assistant_stream_event import (\n    ThreadRunRequiresAction,\n    ThreadMessageDelta,\n    ThreadRunFailed,\n    ThreadRunCancelling,\n    ThreadRunCancelled,\n    ThreadRunExpired,\n    ThreadRunStepFailed,\n    ThreadRunStepCancelled,\n)\n\nfrom ..config.main import config\nfrom ..config.prompts import SYS_PROMPT\nfrom ..utils.singleton import Singleton\nfrom ..services.assistant_setup import AssistantSetup\nfrom ..tools.definitions import GET_WEATHER_INFORMATION\nfrom ..tools.get_weather import get_weather_information\n\nos.environ[\"OPENAI_API_KEY\"] = config.OPENAI_API_KEY\n\nclass ChatService(metaclass=Singleton):\n    \"\"\"\n    This class is used to handle the OpenAI GPT based assistant.\n    \"\"\"\n\n    assistant: Assistant = None\n    assistant_setup: AssistantSetup = None\n    sys_prompt: str = SYS_PROMPT\n    chat_to_thread_map = {}\n    tools = []\n    tool_instances = {}\n\n    def __init__(self) -> None:\n        self.client = OpenAI()\n        self.name = 'Activity Suggester'\n        self.assistant_id = config.ASSISTANT_ID\n        self.init_tools()\n        self.initialize()\n\n    def initialize(self):\n        \"\"\"\n        This function initializes the required services and objects.\n        \"\"\"\n        self.assistant_setup = AssistantSetup(\n            self.client,\n            self.assistant_id,\n            self.sys_prompt,\n            self.name,\n            self.tools,\n        )\n\n    async def create_assistant(self):\n        \"\"\"\n        This function creates assistant if not exists\n        \"\"\"\n        if not self.assistant:\n            self.assistant = (  # pylint: disable=attribute-defined-outside-init\n                await self.assistant_setup.create_or_update_assistant()\n            )\n\n    async def generate(self, chat_id, content):\n        \"\"\"\n        It generates the response for the user query.\n        \"\"\"\n        await self.create_assistant()\n        thread = await self.create_or_get_thread(chat_id)\n        await self.client.beta.threads.messages.create(\n            thread.id,\n            role=\"user\",\n            content=content,\n        )\n        stream = await self.client.beta.threads.runs.create(\n            thread_id=thread.id, assistant_id=self.assistant.id, stream=True\n        )\n        async for event in stream:\n            async for token in self.process_event(event, thread):\n                yield token\n\n        print(\"Tool run completed\")\n\n    async def create_or_get_thread(self, chat_id) -> Thread:\n        \"\"\"\n        This function either creates a new thread for the chat_id or gets the existing thread.\n        \"\"\"\n        thread = None\n        if self.chat_to_thread_map.get(chat_id):\n            try:\n                thread = await self.client.beta.threads.retrieve(self.chat_to_thread_map[chat_id])\n            except Exception as e:  # pylint: disable=bare-except, broad-except\n                print(\"Error in getting thread\", e)\n                thread = None\n        if not thread:\n            thread = await self.client.beta.threads.create(\n                metadata={\n                    \"chat_id\": str(chat_id),\n                },\n            )\n            self.chat_to_thread_map[chat_id] = thread.id\n        return thread\n\n    def create_tool_output(self, tool_call, tool_result):\n        \"\"\"\n        This function creates the tool output.\n        \"\"\"\n        output = {\n            \"tool_call_id\": tool_call.id,\n            \"output\": tool_result,\n        }\n        return output\n\n    async def process_event(self, event, thread: Thread, **kwargs):\n        \"\"\"\n        Process an event in the thread.\n\n        Args:\n            event: The event to be processed.\n            thread: The thread object.\n            **kwargs: Additional keyword arguments.\n\n        Yields:\n            The processed tokens.\n\n        Raises:\n            Exception: If the run fails.\n        \"\"\"\n        if isinstance(event, ThreadMessageDelta):\n            data = event.data.delta.content\n            for d in data:\n                yield d\n\n        elif isinstance(event, ThreadRunRequiresAction):\n            run_obj = event.data\n            tool_outputs = await self.process_tool_calls(\n                run_obj.required_action.submit_tool_outputs.tool_calls\n            )\n            tool_output_events = (\n                await self.client.beta.threads.runs.submit_tool_outputs(\n                    thread_id=thread.id,\n                    run_id=run_obj.id,\n                    tool_outputs=tool_outputs,\n                    stream=True,\n                )\n            )\n            async for tool_event in tool_output_events:\n                async for token in self.process_event(\n                    tool_event, thread=thread, **kwargs\n                ):\n                    yield token\n\n        elif any(\n            isinstance(event, cls)\n            for cls in [\n                ThreadRunFailed,\n                ThreadRunCancelling,\n                ThreadRunCancelled,\n                ThreadRunExpired,\n                ThreadRunStepFailed,\n                ThreadRunStepCancelled,\n            ]\n        ):\n            raise Exception(\"Run failed\") # pylint: disable=broad-exception-raised\n\n    def init_tools(self):\n        \"\"\"\n        This function initializes the tools.\n        \"\"\"\n        self.tools = [GET_WEATHER_INFORMATION]\n        self.tool_instances = {\n            \"get_weather_information\": get_weather_information,\n        }\n\n    async def process_tool_call(self, tool_call, tool_outputs: list, extra_args=None):\n        \"\"\"\n        This function processes a single tool call.\n        And also handles the exceptions.\n        \"\"\"\n        result = None\n        try:\n            arguments = json.loads(tool_call.function.arguments)\n            function_name = tool_call.function.name\n            if extra_args:\n                for key, value in extra_args.items():\n                    arguments[key] = value\n            if function_name not in self.tool_instances:\n                result = \"Tool not found\"\n            else:\n                result = await self.tool_instances[function_name](**arguments)\n        except Exception as e:  # pylint: disable=broad-except\n            result = str(e)\n            print(e)\n        created_tool_output = self.create_tool_output(tool_call, result)\n        tool_outputs.append(created_tool_output)\n\n    async def process_tool_calls(self, tool_calls, extra_args = None):\n        \"\"\"\n        This function processes all the tool calls.\n        \"\"\"\n        tool_outputs = []\n        coroutines = []\n        total_calls = len(tool_calls)\n        for i in range(total_calls):\n            tool_call = tool_calls[i]\n            coroutines.append(self.process_tool_call(tool_call, tool_outputs, extra_args))\n        if coroutines:\n            await asyncio.gather(*coroutines)\n        return tool_outputs\n",
  "templates/index.html": "<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Weather Advisor Chat</title>\n    <script src=\"https://cdn.tailwindcss.com\"></script>\n    <script src=\"https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js\"></script>\n    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n</head>\n\n<body class=\"bg-gray-100 p-6\">\n    <div class=\"container mx-auto\">\n        <h1 class=\"text-3xl font-bold mb-6\">Weather Advisor Chat</h1>\n\n        <div class=\"mb-4\">\n            <label for=\"voice-select\" class=\"block text-sm font-medium text-gray-700\">Select Voice:</label>\n            <select id=\"voice-select\"\n                class=\"mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm rounded-md\">\n                <option value=\"\" disabled selected>Select a Voice</option>\n            </select>\n        </div>\n\n        <div id=\"chat-window\">\n            <div id=\"chat-box\" class=\"border border-gray-300 p-4 rounded-md mb-4 h-96 overflow-y-auto bg-white\"></div>\n            <div class=\"flex items-center\">\n                <textarea type=\"text\" id=\"message-input\"\n                    class=\"flex-grow border-gray-300 rounded-md shadow-sm focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm mr-2 p-2\"\n                    placeholder=\"Type your message\"></textarea>\n                <button id=\"mic-button\" class=\"px-4 py-2 bg-indigo-600 text-white rounded-md shadow-sm\">🎤</button>\n                <button id=\"send-button\"\n                    class=\"ml-2 px-4 py-2 bg-green-600 text-white rounded-md shadow-sm\">Send</button>\n                <button id=\"stop-speech-button\"\n                    class=\"ml-2 px-4 py-2 bg-red-600 text-white rounded-md shadow-sm\">Stop Speech</button>\n            </div>\n        </div>\n    </div>\n\n    <script>\n        const chatWindow = document.getElementById('chat-window');\n        const chatBox = document.getElementById('chat-box');\n        const messageInput = document.getElementById('message-input');\n        const micButton = document.getElementById('mic-button');\n        const sendButton = document.getElementById('send-button');\n        const stopSpeechButton = document.getElementById('stop-speech-button');\n\n        let isRecording = false;\n        let recognition;\n        let finalTranscript = '';\n\n        micButton.addEventListener('click', () => {\n            if (!isRecording) {\n                startRecognition();\n            } else {\n                stopRecognition();\n            }\n        });\n\n        sendButton.addEventListener('click', async () => {\n            const message = messageInput.value.trim();\n            if (message) {\n                appendMessage('🗣️', message);\n                messageInput.value = '';\n                await sendMessage(message);\n                messageInput.focus();\n            }\n        });\n\n        stopSpeechButton.addEventListener('click', stopSpeech);\n\n        function getJson(s) {\n            s = s.slice(s.search(/[\\[{]/));\n            try {\n                return JSON.parse(s);\n            } catch (e) {\n                return JSON.parse(s.slice(0, e.message.match(/position (\\d+)/)[1]));\n            }\n        }\n\n        function startRecognition() {\n            isRecording = true;\n            micButton.textContent = 'Stop 🎤';\n\n            recognition = new webkitSpeechRecognition();\n            recognition.interimResults = true;\n            recognition.continuous = true;\n            recognition.lang = 'cs-CZ';  // Nastavení češtiny pro rozpoznávání řeči\n\n            recognition.onresult = (event) => {\n                let interimTranscript = '';\n                for (let i = event.resultIndex; i < event.results.length; ++i) {\n                    if (event.results[i].isFinal) {\n                        finalTranscript += event.results[i][0].transcript;\n                    } else {\n                        interimTranscript += event.results[i][0].transcript;\n                    }\n                }\n                messageInput.value = finalTranscript + interimTranscript;\n            };\n\n            recognition.start();\n        }\n\n        function stopRecognition() {\n            isRecording = false;\n            micButton.textContent = '🎤';\n            recognition.stop();\n            appendMessage('🗣️', finalTranscript);\n            sendMessage(finalTranscript);\n            messageInput.value = '';\n            finalTranscript = '';\n        }\n\n        function stopSpeech() {\n            if (window.speechSynthesis.speaking) {\n                window.speechSynthesis.cancel();\n            }\n        }\n\n        function uuidv4() {\n            return \"10000000-1000-4000-8000-100000000000\".replace(/[018]/g, c =>\n                (+c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> +c / 4).toString(16)\n            );\n        }\n        const chatId = uuidv4();\n        async function sendMessage(message) {\n            try {\n                const response = await fetch(`/chat/${chatId}`, {\n                    method: 'POST',\n                    headers: { 'Content-Type': 'application/json' },\n                    body: JSON.stringify({\n                        \"user_query\": message,\n                    })\n                })\n\n                if (!response.body) {\n                    throw new Error('ReadableStream not supported');\n                }\n\n                const reader = response.body.getReader();\n                const decoder = new TextDecoder();\n                let done = false;\n                const newMessage = appendMessage('🤖', '');\n                const m = newMessage.querySelector('.msg');\n                let msgContents = ''\n                while (!done) {\n                    const { value, done: streamDone } = await reader.read();\n                    done = streamDone;\n                    const data = decoder.decode(value, { stream: true });\n                    const chunks = data.split('\\n');\n                    for (chunk in chunks) {\n                        try {\n                            let message = getJson(chunks[chunk]);\n                            message = message?.text?.value;\n                            console.log(\"Parsed Message\", message);\n                            msgContents += message;\n                            m.innerHTML = marked.parse(msgContents);\n                        } catch (error) { }\n                    }\n                }\n                speakText(msgContents);\n            } catch (error) {\n                console.error('Error sending message:', error);\n            }\n        }\n\n        function appendMessage(sender, message) {\n            const messageElement = document.createElement('div');\n            messageElement.classList.add('mb-2');\n            messageElement.innerHTML = `<strong>${sender}:</strong>\\n<span class=\"msg\">${message}</span>`;\n            chatBox.appendChild(messageElement);\n            chatBox.scrollTop = chatBox.scrollHeight;\n            // get the messageElement from chatBox\n            const newMessage = chatBox.children[chatBox.children.length - 1];\n            return newMessage;\n        }\n\n        const synth = window.speechSynthesis;\n        const voiceSelect = document.querySelector(\"#voice-select\");\n\n        let voices;\n\n        function loadVoices() {\n            voices = synth.getVoices();\n            voiceSelect.innerHTML = '';\n            voices.forEach((voice, i) => {\n                if (voice.lang.startsWith('cs-') || voice.lang.startsWith('en-')) {\n                    const option = document.createElement(\"option\");\n                    option.textContent = `${voice.name} (${voice.lang})`;\n                    option.value = i;\n                    voiceSelect.appendChild(option);\n                }\n            });\n            console.log(\"Dostupné hlasy:\", voices);\n        }\n\n        if (\"onvoiceschanged\" in synth) {\n            synth.onvoiceschanged = loadVoices;\n        } else {\n            loadVoices();\n        }\n\n        function speakText(text) {\n            if (window.speechSynthesis.speaking) {\n                window.speechSynthesis.cancel();\n            }\n            const utterance = new SpeechSynthesisUtterance(text);\n            utterance.voice = voices[voiceSelect.value];\n            utterance.rate = 1.1;\n            utterance.pitch = 1.1;\n            window.speechSynthesis.speak(utterance);\n        }\n    </script>\n</body>\n\n</html>"
}